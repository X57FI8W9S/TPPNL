{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 16:46:11.991214: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-04 16:46:15.181760: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-04 16:46:24.146128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Seleccionar un corpus de texto\n",
        "Utilizaremos como dataset \"Así habló Zaratustra\", de Friedrich Nietzsche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen('https://www.textos.info/friedrich-nietzsche/asi-hablo-zaratustra/ebook')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remover \\xad \\n\n",
        "article_text = article_text.replace('\\xad', '').replace('\\n', '')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WBE0sSYuB-E6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' cuando zaratustra tenía treinta años abandonó su patria y el lago de su patria y marchó a las montañas. allí gozó de su espíritu y de su soledad y durante diez años no se cansó de hacerlo. pero al fin su corazón se transformó y una mañana, levantándose con la aurora, se colocó delante del sol y le habló así: «¡tú gran astro! ¡qué sería de tu felicidad si no tuvieras a aquellos a quienes iluminas! durante diez años has venido subiendo hasta mi caverna: sin mí, mi águila y mi serpiente te habrías hartado de tu luz y de este camino. pero nosotros te aguardábamos cada mañana, te liberábamos de tu sobreabundancia y te bendecíamos por ello. ¡mira! estoy hastiado de mi sabiduría como la abeja que ha recogido demasiada miel, tengo necesidad de manos que se extiendan. me gustaría regalar y repartir hasta que los sabios entre los hombres hayan vuelto a regocijarse con su locura y los pobres, con su riqueza. para ello tengo que bajar a la profundidad como haces tú al atardecer, cuando traspones '"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocesamiento, tokenización, dataset, train/val\n",
        "\n",
        "\n",
        "Construcción del vocabulario de caracteres, tokenizción del texto a índices de caracteres, armado de secuencias de longitud fija, definición X e y en esquema many-to-many (target desplazado un paso) y separación de una porción del corpus para validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VwTK6xgLJd8q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Zd2OkfQYs2Q7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/rnyx/Tapioka/TPs/TPPNL/.venv/lib/python3.12/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "2025-12-04 16:46:41.597646: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,065</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m53,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)       │        \u001b[38;5;34m13,065\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,265</span> (258.85 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,265\u001b[0m (258.85 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,265</span> (258.85 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,265\u001b[0m (258.85 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oQq1PHDkxDvN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.3440\n",
            " mean perplexity: 6.117129584155924 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 79ms/step - loss: 2.1043\n",
            "Epoch 2/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.8349\n",
            " mean perplexity: 5.432499770558746 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 77ms/step - loss: 1.8051\n",
            "Epoch 3/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.7459\n",
            " mean perplexity: 5.245089186289832 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - loss: 1.7348\n",
            "Epoch 4/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.7087\n",
            " mean perplexity: 5.218350076984662 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - loss: 1.7032\n",
            "Epoch 5/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6881\n",
            " mean perplexity: 5.1400499005825715 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - loss: 1.6842\n",
            "Epoch 6/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6730\n",
            " mean perplexity: 5.036991924868969 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - loss: 1.6707\n",
            "Epoch 7/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6626\n",
            " mean perplexity: 4.955078999352743 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - loss: 1.6605\n",
            "Epoch 8/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6542\n",
            " mean perplexity: 4.98571231345377 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.6526\n",
            "Epoch 9/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6482\n",
            " mean perplexity: 4.9772258685393815 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.6468\n",
            "Epoch 10/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.6429\n",
            " mean perplexity: 5.030227378313257 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 78ms/step - loss: 1.6420\n",
            "Epoch 11/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.6392\n",
            " mean perplexity: 5.047982072436101 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 78ms/step - loss: 1.6377\n",
            "Epoch 12/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.6349\n",
            " mean perplexity: 4.90150038571848 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 80ms/step - loss: 1.6340\n",
            "Epoch 13/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.6316\n",
            " mean perplexity: 4.912090393300649 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 78ms/step - loss: 1.6309\n",
            "Epoch 14/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.6301\n",
            " mean perplexity: 4.88341083677212 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 78ms/step - loss: 1.6291\n",
            "Epoch 15/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.6263\n",
            " mean perplexity: 4.876736330442732 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 79ms/step - loss: 1.6262\n",
            "Epoch 16/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.6243\n",
            " mean perplexity: 4.874934241380581 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 79ms/step - loss: 1.6243\n",
            "Epoch 17/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.6224\n",
            " mean perplexity: 4.879004927906576 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 80ms/step - loss: 1.6221\n",
            "Epoch 18/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.6213\n",
            " mean perplexity: 4.874306104708163 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 80ms/step - loss: 1.6206\n",
            "Epoch 19/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.6196\n",
            " mean perplexity: 4.880357941704104 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 80ms/step - loss: 1.6189\n",
            "Epoch 20/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.6177\n",
            " mean perplexity: 4.8440483897510624 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 80ms/step - loss: 1.6176\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HNyBykvhzs7-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/rnyx/Tapioka/TPs/TPPNL/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habló así: «¡qué es la vida de la vida d'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='habló así:'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"habló así: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([61, 39, 28, 57,  2,  3, 39, 58, 33, 11,  3, 39, 58, 33,  3, 61, 39,\n",
              "       28, 57,  2,  3, 43, 39, 21, 39, 48,  8, 58, 48, 21, 39])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habló así: así habló zaratustra'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
