{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 22:53:00.261007: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-04 22:53:03.483814: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-04 22:53:13.337682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# Si por alguna razón querés forzar CPU, descomenta esta línea:\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### 1. Selección del corpus de texto\n",
        "Utilizaremos como dataset \"Así habló Zaratustra\", de Friedrich Nietzsche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen('https://www.textos.info/friedrich-nietzsche/asi-hablo-zaratustra/ebook')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remover \\xad \\n\n",
        "article_text = article_text.replace('\\xad', '').replace('\\n', '')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WBE0sSYuB-E6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' cuando zaratustra tenía treinta años abandonó su patria y el lago de su patria y marchó a las montañas. allí gozó de su espíritu y de su soledad y durante diez años no se cansó de hacerlo. pero al fin su corazón se transformó y una mañana, levantándose con la aurora, se colocó delante del sol y le habló así: «¡tú gran astro! ¡qué sería de tu felicidad si no tuvieras a aquellos a quienes iluminas! durante diez años has venido subiendo hasta mi caverna: sin mí, mi águila y mi serpiente te habrías hartado de tu luz y de este camino. pero nosotros te aguardábamos cada mañana, te liberábamos de tu sobreabundancia y te bendecíamos por ello. ¡mira! estoy hastiado de mi sabiduría como la abeja que ha recogido demasiada miel, tengo necesidad de manos que se extiendan. me gustaría regalar y repartir hasta que los sabios entre los hombres hayan vuelto a regocijarse con su locura y los pobres, con su riqueza. para ello tengo que bajar a la profundidad como haces tú al atardecer, cuando traspones '"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Preprocesamiento, tokenización y construcción del dataset\n",
        "\n",
        "\n",
        "Construcción del vocabulario de caracteres, tokenizción del texto a índices de caracteres, armado de secuencias de longitud fija, definición X e y en esquema many-to-many (target desplazado un paso) y separación de una porción del corpus para validación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VwTK6xgLJd8q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "### 3. Modelo de basado en SimpleRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo recibe secuencias de caracteres codificados en one-hot mediante una capa CategoryEncoding aplicada en el tiempo. Sobre esta entrada actúa una SimpleRNN con 200 unidades, con dropout y recurrent_dropout para mitigar el sobreajuste. Cada estado oculto se pasa luego por una capa densa con softmax, obteniendo para cada posición una distribución de probabilidad sobre el siguiente carácter, entrenada con sparse_categorical_crossentropy y el optimizador rmsprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Zd2OkfQYs2Q7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/rnyx/Tapioka/TPs/TPPNL/.venv/lib/python3.12/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "2025-12-04 22:53:32.008223: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2025-12-04 22:53:32.008286: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: DEATHSTAR\n",
            "2025-12-04 22:53:32.008289: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: DEATHSTAR\n",
            "2025-12-04 22:53:32.008395: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 580.95.5\n",
            "2025-12-04 22:53:32.008403: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 580.95.5\n",
            "2025-12-04 22:53:32.008405: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:248] kernel version seems to match DSO: 580.95.5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m53,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m12,864\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,864</span> (257.28 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,864\u001b[0m (257.28 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,864</span> (257.28 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,864\u001b[0m (257.28 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "### 4. Entrenamiento y perplejidad en datos de validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oQq1PHDkxDvN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.3432\n",
            " mean perplexity: 6.119241517905406 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 79ms/step - loss: 2.0999\n",
            "Epoch 2/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.8336\n",
            " mean perplexity: 5.57587438678074 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 77ms/step - loss: 1.8038\n",
            "Epoch 3/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.7435\n",
            " mean perplexity: 5.260205305176019 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.7326\n",
            "Epoch 4/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.7067\n",
            " mean perplexity: 5.118488540448025 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.7009\n",
            "Epoch 5/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6862\n",
            " mean perplexity: 5.006934549732297 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 77ms/step - loss: 1.6823\n",
            "Epoch 6/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6722\n",
            " mean perplexity: 4.9537670200626165 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - loss: 1.6693\n",
            "Epoch 7/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6607\n",
            " mean perplexity: 4.946613679200281 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 76ms/step - loss: 1.6592\n",
            "Epoch 8/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6537\n",
            " mean perplexity: 4.90087967632089 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 75ms/step - loss: 1.6524\n",
            "Epoch 9/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6474\n",
            " mean perplexity: 4.943493295404221 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 78ms/step - loss: 1.6460\n",
            "Epoch 10/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6430\n",
            " mean perplexity: 4.899024734934207 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.6415\n",
            "Epoch 11/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6391\n",
            " mean perplexity: 4.853286901712004 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.6379\n",
            "Epoch 12/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6351\n",
            " mean perplexity: 4.803913528235992 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.6342\n",
            "Epoch 13/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6311\n",
            " mean perplexity: 4.816638308511159 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 76ms/step - loss: 1.6310\n",
            "Epoch 14/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6291\n",
            " mean perplexity: 4.845116646620305 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 75ms/step - loss: 1.6283\n",
            "Epoch 15/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6261\n",
            " mean perplexity: 4.770991772877086 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 76ms/step - loss: 1.6256\n",
            "Epoch 16/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6243\n",
            " mean perplexity: 4.750333630645881 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 77ms/step - loss: 1.6233\n",
            "Epoch 17/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6224\n",
            " mean perplexity: 4.8355976749698835 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 76ms/step - loss: 1.6214\n",
            "Epoch 18/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6201\n",
            " mean perplexity: 4.802437153588409 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 75ms/step - loss: 1.6197\n",
            "Epoch 19/20\n",
            "\u001b[1m1887/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6177\n",
            " mean perplexity: 4.749509364419741 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 78ms/step - loss: 1.6177\n",
            "Epoch 20/20\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6173\n",
            " mean perplexity: 4.759143462264484 \n",
            "\n",
            "\u001b[1m1888/1888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 76ms/step - loss: 1.6167\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQpFJREFUeJzt3Xl8VPW9//H3ZJuEkAVCVghLgCTIKoLIpqAoosWlVTRFUYtaEX9VW1ql1SvWBeuCXnsrroitRUXrUoViAQVFQHYEhZANEiALW3YySWbO74+QkQgJGTKZM5O8no/HeUBmzjnzORyG8+ac72IxDMMQAACASfzMLgAAALRvhBEAAGAqwggAADAVYQQAAJiKMAIAAExFGAEAAKYijAAAAFMRRgAAgKkCzC6gORwOhw4ePKiwsDBZLBazywEAAM1gGIbKysqUkJAgP7/G73/4RBg5ePCgEhMTzS4DAACchby8PHXr1q3R930ijISFhUmqO5jw8HCTqwEAAM1RWlqqxMRE53W8MT4RRuofzYSHhxNGAADwMWdqYkEDVgAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABM1a7DyD/W7dXvFm9X3tFKs0sBAKDdatdh5IPN+/WvLfu140CJ2aUAANButeswkhIXJknaXVBmciUAALRf7TqMpMaFS5J255eaXAkAAO1XOw8j3BkBAMBs7TqM1D+myT1aqQpbrcnVAADQPrXrMBLV0aqYMKskKb2QuyMAAJihXYcR6ce7I+k8qgEAwBTtPoz0i6cRKwAAZmr3YSQllkasAACYqd2HkdT4H8OIYRgmVwMAQPvT7sNIn5iO8vezqOR4jQpKq8wuBwCAdqfdhxFrgL+SuoRK4lENAABmaPdhRJJSnY1YCSMAAHgaYUQ/jsSaXkCPGgAAPI0wIoaFBwDATIQR/TjwWWZRuaprHSZXAwBA+0IYkdQ1MkRh1gDVOgxlHy43uxwAANoVwogki8Xy43gjNGIFAMCjCCMnpNBuBAAAUxBGTkiNO9G9lx41AAB4FGHkBGePGh7TAADgUYSRE5JPhJGC0ioVV1abXA0AAO0HYeSE8OBAdY0MkUS7EQAAPIkwcpJ+8fUjsRJGAADwFMLISWjECgCA5xFGTkL3XgAAPM/lMHLgwAHddNNNioqKUkhIiAYOHKhNmzY1uc2qVas0dOhQWa1W9enTRwsXLjzbelvVyY9pHA7D5GoAAGgfXAojx44d0+jRoxUYGKj//Oc/+uGHH/Tcc8+pU6dOjW6Tk5OjK6+8UuPHj9e2bdt033336fbbb9fnn3/e4uLdrWdUqIIC/FRZbVfesUqzywEAoF0IcGXlv/zlL0pMTNSbb77pfK1Xr15NbvPyyy+rV69eeu655yRJ/fr105o1a/T8889r4sSJZ1Fy6wnw91PfmI76/mCpdheUqUdUqNklAQDQ5rl0Z+Tf//63hg0bpuuvv14xMTE699xz9dprrzW5zbp16zRhwoQGr02cOFHr1q1rdBubzabS0tIGi6ekMPgZAAAe5VIYyc7O1vz589W3b199/vnnmjFjhn7zm9/orbfeanSbgoICxcbGNngtNjZWpaWlOn78+Gm3mTt3riIiIpxLYmKiK2W2SL8TPWrSC+lRAwCAJ7gURhwOh4YOHaonn3xS5557ru68807dcccdevnll91a1OzZs1VSUuJc8vLy3Lr/pjB7LwAAnuVSGImPj9c555zT4LV+/fopNze30W3i4uJUWFjY4LXCwkKFh4crJCTktNtYrVaFh4c3WDyl/jFNzpEKHa+2e+xzAQBor1wKI6NHj1Z6enqD1/bs2aMePXo0us3IkSO1cuXKBq8tX75cI0eOdOWjPSa6o1VRoUEyDCmjiLsjAAC0NpfCyP3336/169frySefVGZmphYtWqRXX31VM2fOdK4ze/ZsTZs2zfnzXXfdpezsbP3hD3/Q7t279dJLL2nx4sW6//773XcUbmSxWGjECgCAB7kURoYPH66PPvpI77zzjgYMGKDHHntML7zwgqZOnepcJz8/v8Fjm169emnJkiVavny5Bg8erOeee06vv/6613XrPdmPw8ITRgAAaG0WwzC8fqjR0tJSRUREqKSkxCPtRxZvytMfPvhOo3pHadEdF7T65wEA0BY19/rN3DSnkXrSHDU+kNUAAPBphJHT6BsTJj+LdLSiWofKbWaXAwBAm0YYOY2QIH/1PDEUPI1YAQBoXYSRRqSeNIMvAABoPYSRRqTE1jW02VXAsPAAALQmwkgjuDMCAIBnEEYaUT9hXkZhuWrtDpOrAQCg7SKMNKJbpxB1CPJXtd2hnMMVZpcDAECbRRhphJ/fScPC86gGAIBWQxhpwo+Dn9GIFQCA1kIYaUL9HDU0YgUAoPUQRppQ/5hmFwOfAQDQaggjTah/THOg+LhKq2pMrgYAgLaJMNKEyA5Bio8IliTt4VENAACtgjByBs5HNYQRAABaBWHkDH5sxEqPGgAAWgNh5Ayc3XtpxAoAQKsgjJzByXPUGIZhcjUAALQ9hJEzSOrSUYH+FpXZanWg+LjZ5QAA0OYQRs4gKMBPvaM7SuJRDQAArYEw0gz17UbSCwkjAAC4G2GkGVJO9KjZlU+PGgAA3I0w0gwnN2IFAADuRRhphvrHNNmHK2SrtZtcDQAAbQthpBniwoMVERIou8NQZlG52eUAANCmEEaawWKxMPgZAACthDDSTM4wwrDwAAC4FWGkmVLj63rU7KYRKwAAbkUYaaYU550RwggAAO5EGGmmlNi6MHKozKYj5TaTqwEAoO0gjDRTqDVAPaI6SGK8EQAA3Ikw4oL6uyO7CCMAALgNYcQF9Y1Y0+lRAwCA2xBGXJBKI1YAANyOMOKC+jCyp7BMdodhcjUAALQNhBEX9IgKVXCgn6pqHNp3pMLscgAAaBMIIy7w97MoOZZHNQAAuBNhxEW0GwEAwL1cCiNz5syRxWJpsKSmpja5zQsvvKCUlBSFhIQoMTFR999/v6qqqlpUtJlS4k4MC59PjxoAANwhwNUN+vfvrxUrVvy4g4DGd7Fo0SI9+OCDWrBggUaNGqU9e/bo1ltvlcVi0bx5886uYpP1O3FnJL2QOyMAALiDy2EkICBAcXFxzVp37dq1Gj16tH75y19Kknr27Km0tDR9++23rn6s16ifo2bfkUpV2GoVanX5jxAAAJzE5TYjGRkZSkhIUFJSkqZOnarc3NxG1x01apQ2b96sDRs2SJKys7O1dOlSXXHFFU1+hs1mU2lpaYPFW0R1tCo6zCqprosvAABoGZfCyIgRI7Rw4UItW7ZM8+fPV05OjsaOHauystNflH/5y1/qz3/+s8aMGaPAwED17t1b48aN0x//+McmP2fu3LmKiIhwLomJia6U2epoxAoAgPu4FEYmTZqk66+/XoMGDdLEiRO1dOlSFRcXa/Hixaddf9WqVXryySf10ksvacuWLfrwww+1ZMkSPfbYY01+zuzZs1VSUuJc8vLyXCmz1TnDCI1YAQBosRY1eIiMjFRycrIyMzNP+/7DDz+sm2++WbfffrskaeDAgaqoqNCdd96pP/3pT/LzO30WslqtslqtLSmtVaXW96jhzggAAC3WonFGysvLlZWVpfj4+NO+X1lZeUrg8Pf3lyQZhu8Op55y0mMaXz4OAAC8gUthZNasWVq9erX27t2rtWvX6tprr5W/v7/S0tIkSdOmTdPs2bOd60+ePFnz58/Xu+++q5ycHC1fvlwPP/ywJk+e7AwlvqhPTEf5+1lUcrxGhaU2s8sBAMCnufSYZv/+/UpLS9ORI0cUHR2tMWPGaP369YqOjpYk5ebmNrgT8tBDD8liseihhx7SgQMHFB0drcmTJ+uJJ55w71F4WHCgv3p1CVVmUbl2FZQqLiLY7JIAAPBZFsMHnjOUlpYqIiJCJSUlCg8PN7scSdI9i7bos+/y9cDlqZoxrrfZ5QAA4HWae/1mbpqz1C++7g81vYAeNQAAtARh5CylMHsvAABuQRg5S6nxdWEk61C5qmsdJlcDAIDvIoycpa6RIQqzBqjGbij7cLnZ5QAA4LMII2fJYrE4xxtJ51ENAABnjTDSAvVhZFc+YQQAgLNFGGmB1Pj6YeHpUQMAwNkijLRAPx7TAADQYoSRFkg+EUbyS6pUUlljcjUAAPgmwkgLhAcHqmtkiCQe1QAAcLYIIy2UGsfgZwAAtARhpIXqBz/jzggAAGeHMNJCqXH1PWq4MwIAwNkgjLRQ6kk9ahwOr58AGQAAr0MYaaFeXUIV5O+nymq79h87bnY5AAD4HMJICwX4+6lPTEdJ0i7ajQAA4DLCiBvUN2Jl8DMAAFxHGHGDH7v3cmcEAABXEUbcwNmjhgnzAABwGWHEDeof0+w9UqHj1XaTqwEAwLcQRtwguqNVnUOD5DCkjCLujgAA4ArCiBtYLBaGhQcA4CwRRtwkpT6M0G4EAACXEEbcpJ9zWHh61AAA4ArCiJuknPSYxjAYFh4AgOYijLhJcmyYLBbpaEW1DpXbzC4HAACfQRhxk5Agf/WKCpXESKwAALiCMOJGNGIFAMB1hBE3qh+JlQnzAABoPsKIG9XfGeExDQAAzUcYcaN+J4aFzygqV63dYXI1AAD4BsKIGyV26qAOQf6qrnVo75EKs8sBAMAnEEbcyM/PouTYursju2jECgBAsxBG3Kz+UQ3tRgAAaB7CiJulxNaPxEqPGgAAmoMw4map8Se69/KYBgCAZiGMuFnqie69B4qPq7SqxuRqAADwfoQRN4vsEKS48GBJ0h7ajQAAcEYuhZE5c+bIYrE0WFJTU5vcpri4WDNnzlR8fLysVquSk5O1dOnSFhXt7VLjf5zBFwAANC3A1Q369++vFStW/LiDgMZ3UV1drUsvvVQxMTH64IMP1LVrV+3bt0+RkZFnVayvSIkL06r0QzRiBQCgGVwOIwEBAYqLi2vWugsWLNDRo0e1du1aBQYGSpJ69uzp6kf6nH4n5qhhwjwAAM7M5TYjGRkZSkhIUFJSkqZOnarc3NxG1/33v/+tkSNHaubMmYqNjdWAAQP05JNPym63N/kZNptNpaWlDRZfcvIcNYZhmFwNAADezaUwMmLECC1cuFDLli3T/PnzlZOTo7Fjx6qs7PR3ALKzs/XBBx/Ibrdr6dKlevjhh/Xcc8/p8ccfb/Jz5s6dq4iICOeSmJjoSpmm6x3dUQF+FpXZanWg+LjZ5QAA4NUsRgv+615cXKwePXpo3rx5mj59+invJycnq6qqSjk5OfL395ckzZs3T88884zy8/Mb3a/NZpPNZnP+XFpaqsTERJWUlCg8PPxsy/Woic9/pfTCMr1xyzBd0i/W7HIAAPC40tJSRUREnPH67XKbkZNFRkYqOTlZmZmZp30/Pj5egYGBziAiSf369VNBQYGqq6sVFBR02u2sVqusVmtLSjNdanyY0gvLtLugjDACAEATWjTOSHl5ubKyshQfH3/a90ePHq3MzEw5HA7na3v27FF8fHyjQaStSK1vxEr3XgAAmuRSGJk1a5ZWr16tvXv3au3atbr22mvl7++vtLQ0SdK0adM0e/Zs5/ozZszQ0aNHde+992rPnj1asmSJnnzySc2cOdO9R+GF6kdi3Z3vW41vAQDwNJce0+zfv19paWk6cuSIoqOjNWbMGK1fv17R0dGSpNzcXPn5/ZhvEhMT9fnnn+v+++/XoEGD1LVrV91777164IEH3HsUXqh+4LPswxWqrK5Vh6AWPREDAKDNalEDVk9pbgMYb2IYhi585kvlHT2uV24+TxP7N29sFgAA2ormXr+Zm6aVWCwWTTjRcHX5D4UmVwMAgPcijLSiS8+pCyNf7C6S3eH1N6AAADAFYaQVDe/ZWeHBATpaUa0tucfMLgcAAK9EGGlFgf5+Gp8aI0lawaMaAABOizDSyuof1dBuBACA0yOMtLKLkqMV6G9R9uEKZR0qN7scAAC8DmGklYUFB+qCpChJPKoBAOB0CCMewKMaAAAaRxjxgPrxRjbnHtORctsZ1gYAoH0hjHhAQmSI+ieEyzCklbuLzC4HAACvQhjxkPpHNbQbAQCgIcKIh9Q/qvk647CqauwmVwMAgPcgjHhI/4RwJUQE63iNXd9kHja7HAAAvAZhxEMsFosm0KsGAIBTEEY8qP5RzYpdRXIwcR4AAJIIIx51QVKUOloDdLjcpm37i80uBwAAr0AY8aCgAD9dlBItiV41AADUI4x42GX1XXx3EUYAAJAIIx43LjlG/n4W7Sks174jFWaXAwCA6QgjHhbRIVAjenWWRK8aAAAkwogp6nvVEEYAACCMmKJ+aPhN+47pWEW1ydUAAGAuwogJEjt3UGpcmOwOQ1+mM3EeAKB9I4yY5FJ61QAAIIkwYpr6diOr0w/JVsvEeQCA9oswYpKBXSMUE2ZVRbVd67KOmF0OAACmIYyYxM/vx4nzeFQDAGjPCCMmurR+4rwfimQYTJwHAGifCCMmGtk7Sh2C/FVQWqWdB0rNLgcAAFMQRkwUHOivC/vWTZy3/IcCk6sBAMAchBGT1XfxXb6L8UYAAO0TYcRk41Nj5GeRduWXKu9opdnlAADgcYQRk3UODdKwnnUT562kVw0AoB0ijHiB+l41ywkjAIB2iDDiBerHG/k2+6hKjteYXA0AAJ5FGPECvbqEqk9MR9U6DK3ec8jscgAA8CjCiJeon6tm+Q88qgEAtC+EES9R38V3VXqRqmsdJlcDAIDnuBRG5syZI4vF0mBJTU1t1rbvvvuuLBaLrrnmmrOps80bkhipLh2DVFZVqw05R80uBwAAj3H5zkj//v2Vn5/vXNasWXPGbfbu3atZs2Zp7NixZ1Vke+DvZ9ElqUycBwBof1wOIwEBAYqLi3MuXbp0aXJ9u92uqVOn6tFHH1VSUtJZF9oe1PeqWf5DIRPnAQDaDZfDSEZGhhISEpSUlKSpU6cqNze3yfX//Oc/KyYmRtOnT2/2Z9hsNpWWljZY2oMxfbooONBPB4qPa1d+mdnlAADgES6FkREjRmjhwoVatmyZ5s+fr5ycHI0dO1ZlZae/cK5Zs0ZvvPGGXnvtNZeKmjt3riIiIpxLYmKiS9v7qpAgf43pUz9xHo9qAADtg0thZNKkSbr++us1aNAgTZw4UUuXLlVxcbEWL158yrplZWW6+eab9dprr53xUc5PzZ49WyUlJc4lLy/Ppe192WXn0G4EANC+BLRk48jISCUnJyszM/OU97KysrR3715NnjzZ+ZrDUddlNSAgQOnp6erdu/dp92u1WmW1WltSms8anxoji0XacaBE+SXHFR8RYnZJAAC0qhaNM1JeXq6srCzFx8ef8l5qaqp27Nihbdu2OZerrrpK48eP17Zt29rNoxdXRYdZNbR7J0nSil1FJlcDAEDrc+nOyKxZszR58mT16NFDBw8e1COPPCJ/f3+lpaVJkqZNm6auXbtq7ty5Cg4O1oABAxpsHxkZKUmnvI6GJvSL1eZ9x7Tih0LdfEEPs8sBAKBVuXRnZP/+/UpLS1NKSoqmTJmiqKgorV+/XtHRdY0uc3NzlZ+f3yqFtieXnhMjSVqXdUTltlqTqwEAoHVZDB8Y0KK0tFQREREqKSlReHi42eW0OsMwdPFzq5VzuEIvTR2qKwae+hgMAABv19zrN3PTeCGLxaIJ/erujtDFFwDQ1hFGvNSl58RJkr7YXaRaOxPnAQDaLsKIlxraPVKdOgSq5HiNNu49ZnY5AAC0GsKIlwrw99PFTJwHAGgHCCNerL5XDRPnAQDaMsKIFxvbN1pBAX7KPVqpjKJys8sBAKBVEEa8WKg1QKN7R0miVw0AoO0ijHi5+l41hBEAQFtFGPFyl5wYb2RbXrGKyqpMrgYAAPcjjHi52PBgDe4WIUlaycR5AIA2iDDiAy4950QXXx7VAADaIMKID5hwIoysyTysymomzgMAtC2EER+QEhumxM4hstU69HXGYbPLAQDArQgjPqBu4ry6uyP0qgEAtDWEER9R327ki91FsjsYjRUA0HYQRnzE8J6dFR4coKMV1dqay8R5AIC2gzDiIwL9/XRx6o9z1QAA0FYQRnxIfa+a5cziCwBoQwgjPuSi5GgF+luUfahCWYeYOA8A0DYQRnxIWHCgLkiqmziPAdAAAG0FYcTH1Peqod0IAKCtIIz4mPrxRjbnHtORcpvJ1QAA0HKEER+TEBmi/gnhMgxp5W4mzgMA+D7CiA9i4jwAQFtCGPFB9Y9qvs44rKoau8nVAADQMoQRH9Q/IVwJEcE6XmPXN5lMnAcA8G2EER9ksVicA6At21lgcjUAALQMYcRHXTEwXpL04dYD2pZXbG4xAAC0AGHER12QFKWrBifI7jD028XbaDsCAPBZhBEf9uer+ysmzKrsQxV6elm62eUAAHBWCCM+LLJDkP5y3SBJ0oJvcrQu64jJFQEA4DrCiI8bnxKjtPO7S5Jmvb9dZVU1JlcEAIBrCCNtwJ+u7KfEziE6UHxcj3+2y+xyAABwCWGkDehoDdCz1w2WxSK9tylPX+xmZFYAgO8gjLQRI5KiNH10L0nSA//aoWMV1SZXBABA8xBG2pBZE1PUJ6ajDpXZ9PAnO80uBwCAZiGMtCHBgf6aN2Ww/P0s+uy7fH26/aDZJQEAcEaEkTZmULdIzRzfR5L08Cc7VVRaZXJFAAA0zaUwMmfOHFkslgZLampqo+u/9tprGjt2rDp16qROnTppwoQJ2rBhQ4uLRtP+38V9NKBruIora/TghztkGIbZJQEA0CiX74z0799f+fn5zmXNmjWNrrtq1SqlpaXpyy+/1Lp165SYmKjLLrtMBw4caFHRaFqgv5/mTRmioAA/fbG7SIs35ZldEgAAjXI5jAQEBCguLs65dOnSpdF1//nPf+ruu+/WkCFDlJqaqtdff10Oh0MrV65sUdE4s+TYMM26LFmS9OdPf1De0UqTKwIA4PRcDiMZGRlKSEhQUlKSpk6dqtzc3GZvW1lZqZqaGnXu3LnJ9Ww2m0pLSxsscN30MUka3rOTKqrt+v0H2+Vw8LgGAOB9XAojI0aM0MKFC7Vs2TLNnz9fOTk5Gjt2rMrKypq1/QMPPKCEhARNmDChyfXmzp2riIgI55KYmOhKmTjB38+iZ68frA5B/lqffVQL1+41uyQAAE5hMVrQurG4uFg9evTQvHnzNH369CbXfeqpp/T0009r1apVGjRoUJPr2mw22Ww258+lpaVKTExUSUmJwsPDz7bcduvt9fv00Mc7ZQ3w05LfjFWfmI5mlwQAaAdKS0sVERFxxut3i7r2RkZGKjk5WZmZmU2u9+yzz+qpp57Sf//73zMGEUmyWq0KDw9vsODsTR3RXWP7dpGt1qHfvb9dtXaH2SUBAODUojBSXl6urKwsxcfHN7rO008/rccee0zLli3TsGHDWvJxOEsWi0VPXzdIYcEB2p5XrPmrsswuCQAAJ5fCyKxZs7R69Wrt3btXa9eu1bXXXit/f3+lpaVJkqZNm6bZs2c71//LX/6ihx9+WAsWLFDPnj1VUFCggoIClZeXu/cocEbxESH689X9JUn/uzJD3x8sMbkiAADquBRG9u/fr7S0NKWkpGjKlCmKiorS+vXrFR0dLUnKzc1Vfn6+c/358+erurpa1113neLj453Ls88+696jQLNcM6SrLu8fp1qHod++t122WrvZJQEA0LIGrJ7S3AYwOLMj5TZNfOErHS6v1l0X9daDkxofQRcAgJbwSANW+J6ojlY9ce1ASdKrX2Vp876jJlcEAGjvCCPt0MT+cfr50K5yGNLvFm9XZXWt2SUBANoxwkg79cjk/oqPCNbeI5V66j+7zS4HANCOEUbaqYiQQD1z3WBJ0t/X7dOajMMmVwQAaK8II+3YmL5dNG1kD0nS7z/YrpLjNSZXBABojwgj7dyDk1LVM6qD8kuq9Oin35tdDgCgHSKMtHMdggL03JTB8rNIH245oM+/LzC7JABAO0MYgc7r0Vl3XthbkvSnj3boSLntDFsAAOA+hBFIku6/tK9SYsN0uLxaf/pop3xgLDwAQBtBGIEkyRrgr+emDFaAn0XLvi/Qx9sOmF0SAKCdIIzAaUDXCN17SV9J0v988r3yS46bXBEAoD0gjKCBGeN6a3BipMqqavXAv3bwuAYA0OoII2ggwN9Pz10/WNYAP32155Be/zrH7JIAAG0cYQSn6BPTUX+8op8k6cn/7NKynXT3BQC0HsIITmvayB666YLuMgzpvve2amvuMbNLAgC0UYQRnJbFYtGcyf01PiVaVTUO3f7WJuUeqTS7LABAG0QYQaMC/P30f78cqv4J4TpSUa1bF25QcWW12WUBANoYwgiaFGoN0IJbhys+IljZhyr0639slq3WbnZZAIA2hDCCM4oND9abtw1XR2uAvs05qgc++I4uvwAAtyGMoFlS48I1/6ahCvCz6ONtB/X88j1mlwQAaCMII2i2sX2j9cS1AyRJL36RqcWb8kyuCADQFhBG4JIbhnfXPeP7SJL++OEOrck4bHJFAABfRxiBy353WbKuHpKgWoehGW9vVnpBmdklAQB8GGEELrNYLHr6ukE6v2dnldlqddubG1RYWmV2WQAAH0UYwVmxBvjr1WnnKSk6VAdLqjT9rY2qsNWaXRYAwAcRRnDWIjsEaeGt5ysqNEg7D5Tq/72zVbV2h9llAQB8DGEELdI9qoNeu2WYrAF++mJ3kR799AfGIAEAuIQwghYb2r2TXrhhiCwW6R/r9+mNNTlmlwQA8CGEEbjFpIHx+tMV/SRJTyzdpf/syDe5IgCAryCMwG2mj+mlaSN7yDCk+97bpi25x8wuCQDgAwgjcBuLxaL/+dk5uiQ1RrZah+54a5P2HakwuywAgJcjjMCtAvz99GLauRrQNVxHKqp125sbVVxZbXZZAAAvRhiB24VaA7TgluHqGhmi7MMVuvPvm2WrtZtdFgDASxFG0CpiwoP15m3DFWYN0Ia9R/X797+Tw0GXXwDAqQgjaDXJsWF6+ebzFOBn0b+3H9S85XvMLgkA4IUII2hVo/t00dyfD5Qk/d+XmXpvY67JFQEAvA1hBK3u+mGJ+s0lfSVJf/xop77ac8jkigAA3oQwAo+4f0Jf/fzcrrI7DN39zy3aXVBqdkkAAC/hUhiZM2eOLBZLgyU1NbXJbd5//32lpqYqODhYAwcO1NKlS1tUMHyTxWLRU78YpAuSOqvcVqvb3tyowtIqs8sCAHgBl++M9O/fX/n5+c5lzZo1ja67du1apaWlafr06dq6dauuueYaXXPNNdq5c2eLioZvCgrw0ys3DVPv6FDll1Tp1jc3KrOozOyyAAAmsxguTLE6Z84cffzxx9q2bVuz1r/hhhtUUVGhzz77zPnaBRdcoCFDhujll19udpGlpaWKiIhQSUmJwsPDm70dvFPe0Upd+9I3OlxeLX8/i24Ynqj7JvRVTFiw2aUBANyouddvl++MZGRkKCEhQUlJSZo6dapycxvvHbFu3TpNmDChwWsTJ07UunXrmvwMm82m0tLSBgvajsTOHfSvGaN02TmxsjsMLfo2V+OeWaX/XZGhyupas8sDAHiYS2FkxIgRWrhwoZYtW6b58+crJydHY8eOVVnZ6W+1FxQUKDY2tsFrsbGxKigoaPJz5s6dq4iICOeSmJjoSpnwAT2iQvXqtGFa/OuRGpIYqcpqu55fsUcXPbNK72zIVa3dYXaJAAAPcSmMTJo0Sddff70GDRqkiRMnaunSpSouLtbixYvdWtTs2bNVUlLiXPLy8ty6f3iP83t11kd3j9L//fJcde/cQYfKbJr94Q5N+t+vtXJXoVx4iggA8FEBLdk4MjJSycnJyszMPO37cXFxKiwsbPBaYWGh4uLimtyv1WqV1WptSWnwIRaLRT8blKDLzonT2+v36cUvMpRRVK7pb23SBUmd9ccr+mlQt0izywQAtJIWjTNSXl6urKwsxcfHn/b9kSNHauXKlQ1eW758uUaOHNmSj0UbFRTgp1+N6aXVvx+vuy7qraAAP63PPqqr/u8b/eadrco7Wml2iQCAVuBSGJk1a5ZWr16tvXv3au3atbr22mvl7++vtLQ0SdK0adM0e/Zs5/r33nuvli1bpueee067d+/WnDlztGnTJt1zzz3uPQq0KREhgXpwUqq+nDVOPz+3qywW6d/bD+qS51briSU/qLiy2uwSAQBu5FIY2b9/v9LS0pSSkqIpU6YoKipK69evV3R0tCQpNzdX+fn5zvVHjRqlRYsW6dVXX9XgwYP1wQcf6OOPP9aAAQPcexRok7pGhmjeDUP06T1jNLpPlKrtDr32dY4uemaVXvsqW7Zau9klAgDcwKVxRszCOCMwDEOr9xzSU//Zrd0Fdb23unUK0e8npmjyoAT5+VlMrhAA8FPNvX4TRuBT7A5D/9qyX8/9N12FpTZJ0qBuEZo9qZ9G9o4yuToAwMkII2jTjlfb9caabL28OlvltrqB0i5JjdGDk1LVNzbM5OoAABJhBO3E4XKbXlyZoUXf5qrWYcjPIt0wPFH3T0hWTDjDywOAmQgjaFeyD5Xr6WXpWvZ93ei+IYH+uqx/rKJCrerUIVCRoUHq1CFQnToEKfLEr506BCkkyN/kygGg7SKMoF3atPeonly6S1tyi5u1vjXAzxlQIp1h5TTBJTTwxOtBiggJlD8NZgHgjAgjaLfqe96kF5TpWGWNiiurdayy+qTf1/1aYz+7v/oWixQZEqjxqTGacVFvn2ujUl3rkMMwFBzIXSEArYswAjTBMAxVVNt1rKJaxZU1J8LKj78v/klwOXbi9bKqU2cVvuycWN09vo+GJEZ6/kBccLD4uN5at1fvfJur4zV2XTW4q+68MEkpcb4VpgD4DsII0Apq7A6VHK9RzuEKvfF1jrONiiSN6h2lu8f10eg+UbJYvOcxzra8Yr2xJkdLd+TL7jj1635xaozuvDBJI3p19qq6Afg+wgjgAZlFZZq/KlufbDug2hMX+kHdInT3uN667Jw40wZjq7U79Pn3hVrwTY427zvmfP2CpM6aPiZJUR2D9NpX2Vr2fYHq/wUYnBipuy5M0mX942gTA8AtCCOABx0oPq7XvsrWuxtzVVXjkCT1jg7VXRf11jXndlWgf4vmpGy2kuM1WrwxTwvX7tWB4uOSpEB/i64a3FW/GtNT/RMiGqyfc7hCr3+drfc371d1bV3dPaM66PaxSbruvG60KwHQIoQRwARHym1685u9emvdXmf7koSIYN1xYZJuHN691boS7z1coYVr9+r9TXmqqK6bs6dzaJBuGtFdN43soZiwpsdcOVRm09/X7dXf1+1TyfEaSVJUaJBuGdVTN1/QQ51Cg1qlbgBtG2EEMFFZVY3++W2uXv86R4fL64at7xwapNtG9dS0kT0V0SGwxZ9hGIbWZx/VG2tytHJ3ofNxS3JsR00f00tXD+nq8p2NClutFm/K0+tf5zjvrIQE+uuG4YmaPqaXEjt3aHHdANoPwgjgBapq7Ppg83698lWW8o7WXdxDg/x10wU9NH1Mr7MaJdZWa9dn2/P1xpoc/ZBf6nx9XEq0po/ppTF9urS4IWqt3aElO/L1yups52f4+1l05cB43XlhkgZ0jTjDHgCAMAJ4lfqL+/xVWc5Zh4MC/HTded306wuT1CMq9Iz7OFJu0z+/zdU/1u/TobK6uy3BgX76xdBuum10T/WJcX8XXcMwtCbzsF79KltfZxx2vj6mTxf9+qIktwQfAG0XYQTwQoZh6IvdRXppVZazl4ufRfrZoATNGNdb/eJP/fudXlCmBWty9NG2A85GprHhVk0b2VO/PL+7x9pz7DxQole/ytaSk7oInxMfrl9flKQrB8YrwEONdAH4DsII4MUMw9CGnKN6aVWWVu855Hz94tQYzRjXW+d176TVGYe0YE1OgzsSg7pFaPqYXrpiYLzHeuj8VN7RSr2xJkfvbczT8Zq6xrJdI0M0fUwv3TA8UaHWAFPqAuB9CCOAj9h5oETzV2dp6Y58ZyPUqNAgHamollR35+Syc+I0fWwvDevRyWseixyrqNbb6/dp4dq9zlojQgI1bWQP3TKqp7p0tJpcIQCzEUYAH5NzuEKvrM7Sv7bsV43dUEdrgG4YnqhbR/X06l4s9Y10X/86W3uPVEqqm4DwhuGJumNsklfXDqB1EUYAH1VQUqVd+aUa1rOTwoJb3gXYU+wOQ//9vkAvf5Wt7XnFkup64Fw9OEF3jeutZB+bUBBAyxFGAJjCMAytyzqil1ZlaU3mj+1dLj0nVneP661zu3cysToAnkQYAWC67XnFmr8qS5//8OMcOCOTonT3+N50CwbaAcIIAK+RWVSml1dn6+OtDScUnHFRb03sb96EggBaF2EEgNc53YSCSfUTCg7pqqAAxioB2hLCCACvdaTcpoVr92rhWs9OKAjAswgjALxe/YSCb6zJcQ5x7+4JBQGYhzACwGe0xoSCAMxHGAHgc9wxoSAA70EYAeCzzmZCQQDehzACwOc1NqHgpefE6reXJhNKAC9HGAHQppxuQsErB8brvgl91Zeh5gGvRBgB0CZlFpXphRUZ+uy7fEmSxSJdNThB917SV0nRHU2uzvMKS6v05e4ifbG7SGuzjui8Hp00b8pgRTFrMrwAYQRAm7a7oFQvLM/Qsu8LJNW1Kfn50G76zcV91T2q7c4U7HAY2r6/uC6ApBdp54HSU9aJCw/W36aeq/N6dDahQuBHhBEA7cLOAyV6fvkerdxdJEkK8LPo+mHddM/FfdU1MsTk6tyjtKpGX+85rC92F2n1niIdLq92vmexSIO7ReqS1Bj17xquJ5bsUtahCgX4WfTgpFRNH9Or3c8BVGN36G9fZqq8qlaTBsZraPfIdv9n4imEEQDtyra8Ys1bvkdfnWjoGuhv0Y3Du2vm+D6Ki/CtcUoMw1D24Qp9savu8cvGvUedc/pIUpg1QBcmR2t8aozGpUSry0mPZCpstXrwwx36dPtBSdKkAXH6y3WDFB7cPgeQq7DV6u5/bmnQALprZIh+NjhekwclqH9COMGkFRFGALRLm/Ye1bzle7Q264ikunFKbhrRQ3eNS1JMmPeGElutXRtyjmrlriJ9mV6kfUcqG7yfFB2qS1JjND41RsN7dlagf+Pz+BiGoX+s36fHPvtBNXZDPaM66KWp5+mchPb172dRWZV+tXCjdh4oVXCgny5OjdHq9EOqqLY71+nVJVSTB8Vr8uAEGkK3AsIIgHZtXdYRzVuero1768YpCQ700y0je+rXF/VW59Agk6urU1RapS/Ti7RyV5HWZB5W5UkXySB/P41I6qyLU2N0cWrMWQ34ti2vWDP/uUUHio/LGuCnx68ZoOuHJbrzELxWZlG5bn1zg/YfO66o0CC9fsswndu9k6pq7Ppyd5E+/e6gVu4qkq3W4dwmJTZMkwfH62eDEtSzCwPsuQNhBEC7ZxiG1mQe1nP/3aNtecWS6oaZv3V0T90xNkmRHTwbShwOQ98dKNEXu4v0xe7CUxqfRodZdXFK3d2PMX27qKM1oMWfeayiWvcv3qZV6XWPKW4YlqhHr+6v4MC2Oxnhxr1Hdftbm1RyvEY9ozpo4W3nnzZclNtqtXJXoT7dflCr9xxSjf3Hy+HArhGaPDheVw5KaDNtj8xAGAGAEwzD0Kr0Q5q3fI92HCiRVNfuYvrYXvrVmF5ubU9RbqtV3tFK5R6tVN6JJffEsv/Y8Qb/E5ekwd0idHFqrC5OjVH/hHD5+bm//YLDYeilVZmat3yPHIbULz5c86cObZP/+1+6I1/3vbdN1bUOnds9Uq9PG9asbs4llTX6/PsCffrdQa3NOiL7SW10hvXopJ8NitcVg+K9+lGfN/JIGHnqqac0e/Zs3XvvvXrhhRcaXe+FF17Q/PnzlZubqy5duui6667T3LlzFRzcvJNKGAHgDoZhaPkPhZq3fI9z7puIkEDdeWGSbhnVs1l3ImrtDuWXVDUIGblHK5V37LjyjlbqaEV1k9t3tAZobN8uujg1RuNSYhQd5rnxQL7JPKzfvLNVRyqqFWYN0DPXD9blA+I89vmt7fWvs/XE0l0yjLpRel+88VyFBLl+B+hwuU3/2VmgT7cf1Ma9R52D7PlZpAuSojR5cIIu7x+nTl7yuM+btXoY2bhxo6ZMmaLw8HCNHz++0TCyaNEi/epXv9KCBQs0atQo7dmzR7feeqtuvPFGzZs3z60HAwDN4XAYWvZ9gZ5fvkcZReWSpM6hQfr1hUmaNrKnqmrsJ4WMypPudBzXgeLjDf7XfDqdOgSqe+cOSjyxdD+xJHbqoITIYAU00fi0tRWUVOmeRVu06cScP3eM7aU/XJ7aZINYb+dwGHp8yS4t+CZHkjRtZA89Mrm//N1wl6mgpEpLduTr0+0HnY/6pLou5GP6dtHkQQm6tH9su+2tdCatGkbKy8s1dOhQvfTSS3r88cc1ZMiQRsPIPffco127dmnlypXO1373u9/p22+/1Zo1a5r1eYQRAK3B7jD02XcH9cKKDOUcrpAk+ftZzhg2ggL8lNgppEHQ6NbpRODoHKIwL78w1dgdenrZbr32dd3Fe1iPTvq/Xw71uS7QklRVY9dvF2/T0h11g9/NnpSqOy9MapXuunlHK/XZd3XB5If8H9v7BAX4aVxytG4d1VOj+nRx++f6slYNI7fccos6d+6s559/XuPGjWsyjCxatEh33323/vvf/+r8889Xdna2rrzySt1888364x//eNptbDabbDZbg4NJTEwkjABoFbV2hz7edlAvrsxQ7tG6LrWx4dYf726cCBrdo+p+HxNmbZW2HZ62bGe+fv/+dyqz1apLxyD9743narQPXUyPVVTrjr9v0qZ9xxTob9Gz1w/W1UO6euSzsw6V67Pt+fr39gPKOlThfP2i5Gg9OCmVSRxPaLUw8u677+qJJ57Qxo0bFRwcfMYwIkkvvviiZs2aJcMwVFtbq7vuukvz589vdP05c+bo0UcfPeV1wgiA1lTfHiQ6zNqme5ucbO/hCs345xbtyi+Vn0X67aXJuntcH68PW3lHK3XLmxuUfahCYcEBevXmYRrZO8rjdRiGod0FZXp3Q64WbchVjd2QxSL9Ymg3/e6yZMVHtO+eOK0SRvLy8jRs2DAtX75cgwYNkqQzhpFVq1bpxhtv1OOPP64RI0YoMzNT9957r+644w49/PDDp92GOyMA4DlVNXb9zyc7tXjTfknSuJRoPT9liNc20Nyxv0S3Ldyow+U2JUQEa+GvzleyFwxYtu9IhZ7+PF1LTkziaA3w06/G9NKMcb3bbZuSVgkjH3/8sa699lr5+//4Pwa73S6LxSI/Pz/ZbLYG70nS2LFjdcEFF+iZZ55xvvb222/rzjvvVHl5ufz8ztxoijYjAND6Fm/M08Of7JSt1qGukSH629ShGpIYaXZZDXy5u0gzF21RZbVdqXFhWnjb+V7X1mVr7jHN/c9ubcg5KqmuQfNvLumrqSN6KCjAdxsKn43mXr9d+lO55JJLtGPHDm3bts25DBs2TFOnTtW2bdtOCSKSVFlZeUrgqF/PB4Y4AYB2Y8rwRH1092j1jOqgA8XHdf3La/X3dXu95t/qdzfk6va/b1JltV1j+nTR+3eN9LogIknndu+k9+68QK9PG6Y+MR11rLJGj376gybMW63PvjvoNX+e3qTFg5799DHNtGnT1LVrV82dO1dSXfuPefPm6dVXX3U+ppkxY4bOO+88vffee836DO6MAIDnlFbV6A/vf6dl39f1UJk8OEFP/XygQt0wIuzZMAxDzy/foxe/yJQk/XxoVz3180E+cZeh1u7Q+5v3a97yPTpUVtf8YHC3CM2+op8uSPJ8GxdPa+712+1/s3JzcxvcCXnooYdksVj00EMP6cCBA4qOjtbkyZP1xBNPuPujAQBuEB4cqPk3DdUba3L01H9213VlPViil286z+OTydXYHXrwXzv0ry117Vl+c3Ef3X9pss/MtBvg76e087vr6iEJev3rHL2yOkvb95foxlfXa0K/GD1weSoT9Inh4AEATdi096hmLtqiwlKbQgL9NeGcWA1JjNSQxEj1Twhv1V5HZVU1uvufW/R1xmH5+1n0+DUDlHZ+91b7PE84VGbTiysztGhDruwOQ34W6YbhibpvQrJiw73vkVNLMTcNAMAtDpfbdO+7W/VN5pEGrwf4WdQvPtwZTgYnRiqpS6hbugUXllbp1jc3ald+qUIC/fXS1KEanxrT4v16i6xD5XpmWbrzUVhIoL/uGNtLd17U2y0TJHoLwggAwG3sDkPfZh/Rltxj2pZXrG15xTpcfuo8PGHBAXXBpFtdQBnSPVJdmjFR3cn2FJbp1gUbdLCkSl06BmnBrcM1qFukm47Eu2zed1RPLt2tzSeG548KDdJ9E/rqxvO7e3SI/voo4O7HX4QRAECrMQxDB4qP1wWT3GJt31+sHQdKVFXjOGXdrpEhGtI9UueeuHsyICGi0Qns1mUd0Z3/2KSyqlolRYfqrdvOV2LnDq19OKYyDEOff1+op5ftVvaJaQl6dQnVA5enaGL/uBYFBMMwVHK8RkVlNhWWVqmo1KbCsrpfi8oa/rzkN2PUJ8a97VcIIwAAj6qxO5ReUKbt++sCyra8YmUeKtdPrzL+fhalxoVp8InHO+cmRqp3dEd9tiNfsxZvV7XdoWE9Oum1acO8duC11lBjd+jdjXn63xV7nHedhnaP1B+v6KdhPTs3WNcwDBVX1jiDRGFplYrKbCo68avz5zKbqmtPDYin88/bR7h9OgDCCADAdGVVNdqxv0Rb84q1/cTjnaIy2ynrdbQGqNxWK0maNCBOz98wpN0Myf9T5bZavfpVtl77KlvHa+ySpAuTo9Uh0N8ZPg6V2VRtb17IkKTIDoGKDQtWTLhVMSd+jQ2zKiY8WLEnXosND3Z7d2nCCADA6xiGofySKmcw2ZpXrB37S5wX3dtG99RDV54jfy+fG8cTikqr9PyKDL23MVeNTSTdqUOgYsODFR1mVWx4sGJO+jXmxK9mzrVEGAEA+IRau0MZReXys1iUEseYGz+VUVim//5QqLDggFNChjXAu+8emTboGQAArgjw91O/eP6j2Zi+sWFtfmA07x9LFwAAtGmEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgKsIIAAAwFWEEAACYijACAABM5ROz9hqGIaluKmIAAOAb6q/b9dfxxvhEGCkrK5MkJSYmmlwJAABwVVlZmSIiIhp932KcKa54AYfDoYMHDyosLEwWi8XsclpNaWmpEhMTlZeXp/DwcLPLaVXt6Vil9nW8HGvb1Z6Ol2N1D8MwVFZWpoSEBPn5Nd4yxCfujPj5+albt25ml+Ex4eHhbf4vf732dKxS+zpejrXtak/Hy7G2XFN3ROrRgBUAAJiKMAIAAExFGPEiVqtVjzzyiKxWq9mltLr2dKxS+zpejrXtak/Hy7F6lk80YAUAAG0Xd0YAAICpCCMAAMBUhBEAAGAqwggAADAVYcRD5s6dq+HDhyssLEwxMTG65pprlJ6e3uQ2CxculMViabAEBwd7qOKzN2fOnFPqTk1NbXKb999/X6mpqQoODtbAgQO1dOlSD1Xbcj179jzleC0Wi2bOnHna9X3pvH711VeaPHmyEhISZLFY9PHHHzd43zAM/c///I/i4+MVEhKiCRMmKCMj44z7/dvf/qaePXsqODhYI0aM0IYNG1rpCJqvqWOtqanRAw88oIEDByo0NFQJCQmaNm2aDh482OQ+z+a74ClnOre33nrrKbVffvnlZ9yvr51bSaf9/losFj3zzDON7tNbz21zrjVVVVWaOXOmoqKi1LFjR/3iF79QYWFhk/s92+96cxFGPGT16tWaOXOm1q9fr+XLl6umpkaXXXaZKioqmtwuPDxc+fn5zmXfvn0eqrhl+vfv36DuNWvWNLru2rVrlZaWpunTp2vr1q265pprdM0112jnzp0erPjsbdy4scGxLl++XJJ0/fXXN7qNr5zXiooKDR48WH/7299O+/7TTz+tF198US+//LK+/fZbhYaGauLEiaqqqmp0n++9955++9vf6pFHHtGWLVs0ePBgTZw4UUVFRa11GM3S1LFWVlZqy5Ytevjhh7VlyxZ9+OGHSk9P11VXXXXG/bryXfCkM51bSbr88ssb1P7OO+80uU9fPLeSGhxjfn6+FixYIIvFol/84hdN7tcbz21zrjX333+/Pv30U73//vtavXq1Dh48qJ///OdN7vdsvusuMWCKoqIiQ5KxevXqRtd58803jYiICM8V5SaPPPKIMXjw4GavP2XKFOPKK69s8NqIESOMX//6126uzDPuvfdeo3fv3obD4Tjt+756XiUZH330kfNnh8NhxMXFGc8884zzteLiYsNqtRrvvPNOo/s5//zzjZkzZzp/ttvtRkJCgjF37txWqfts/PRYT2fDhg2GJGPfvn2NruPqd8EspzveW265xbj66qtd2k9bObdXX321cfHFFze5jq+c259ea4qLi43AwEDj/fffd66za9cuQ5Kxbt260+7jbL/rruDOiElKSkokSZ07d25yvfLycvXo0UOJiYm6+uqr9f3333uivBbLyMhQQkKCkpKSNHXqVOXm5ja67rp16zRhwoQGr02cOFHr1q1r7TLdrrq6Wm+//bZ+9atfNTmpo6+e15Pl5OSooKCgwbmLiIjQiBEjGj131dXV2rx5c4Nt/Pz8NGHCBJ873yUlJbJYLIqMjGxyPVe+C95m1apViomJUUpKimbMmKEjR440um5bObeFhYVasmSJpk+ffsZ1feHc/vRas3nzZtXU1DQ4T6mpqerevXuj5+lsvuuuIoyYwOFw6L777tPo0aM1YMCARtdLSUnRggUL9Mknn+jtt9+Ww+HQqFGjtH//fg9W67oRI0Zo4cKFWrZsmebPn6+cnByNHTtWZWVlp12/oKBAsbGxDV6LjY1VQUGBJ8p1q48//ljFxcW69dZbG13HV8/rT9WfH1fO3eHDh2W3233+fFdVVemBBx5QWlpakxOLufpd8CaXX365/v73v2vlypX6y1/+otWrV2vSpEmy2+2nXb+tnNu33npLYWFhZ3xs4Qvn9nTXmoKCAgUFBZ0Sops6T2fzXXeVT8za29bMnDlTO3fuPOPzxZEjR2rkyJHOn0eNGqV+/frplVde0WOPPdbaZZ61SZMmOX8/aNAgjRgxQj169NDixYub9b8NX/bGG29o0qRJSkhIaHQdXz2vqFNTU6MpU6bIMAzNnz+/yXV9+btw4403On8/cOBADRo0SL1799aqVat0ySWXmFhZ61qwYIGmTp16xkblvnBum3ut8QbcGfGwe+65R5999pm+/PJLdevWzaVtAwMDde655yozM7OVqmsdkZGRSk5ObrTuuLi4U1pyFxYWKi4uzhPluc2+ffu0YsUK3X777S5t56vntf78uHLuunTpIn9/f5893/VBZN++fVq+fLnL062f6bvgzZKSktSlS5dGa/f1cytJX3/9tdLT013+Dkved24bu9bExcWpurpaxcXFDdZv6jydzXfdVYQRDzEMQ/fcc48++ugjffHFF+rVq5fL+7Db7dqxY4fi4+NbocLWU15erqysrEbrHjlypFauXNngteXLlze4e+AL3nzzTcXExOjKK690aTtfPa+9evVSXFxcg3NXWlqqb7/9ttFzFxQUpPPOO6/BNg6HQytXrvT6810fRDIyMrRixQpFRUW5vI8zfRe82f79+3XkyJFGa/flc1vvjTfe0HnnnafBgwe7vK23nNszXWvOO+88BQYGNjhP6enpys3NbfQ8nc13/WwKhwfMmDHDiIiIMFatWmXk5+c7l8rKSuc6N998s/Hggw86f3700UeNzz//3MjKyjI2b95s3HjjjUZwcLDx/fffm3EIzfa73/3OWLVqlZGTk2N88803xoQJE4wuXboYRUVFhmGcepzffPONERAQYDz77LPGrl27jEceecQIDAw0duzYYdYhuMxutxvdu3c3HnjggVPe8+XzWlZWZmzdutXYunWrIcmYN2+esXXrVmcPkqeeesqIjIw0PvnkE+O7774zrr76aqNXr17G8ePHnfu4+OKLjb/+9a/On999913DarUaCxcuNH744QfjzjvvNCIjI42CggKPH9/JmjrW6upq46qrrjK6detmbNu2rcF32GazOffx02M903fBTE0db1lZmTFr1ixj3bp1Rk5OjrFixQpj6NChRt++fY2qqirnPtrCua1XUlJidOjQwZg/f/5p9+Er57Y515q77rrL6N69u/HFF18YmzZtMkaOHGmMHDmywX5SUlKMDz/80Plzc77rLUEY8RBJp13efPNN5zoXXXSRccsttzh/vu+++4zu3bsbQUFBRmxsrHHFFVcYW7Zs8XzxLrrhhhuM+Ph4IygoyOjatatxww03GJmZmc73f3qchmEYixcvNpKTk42goCCjf//+xpIlSzxcdct8/vnnhiQjPT39lPd8+bx++eWXp/17W388DofDePjhh43Y2FjDarUal1xyySl/Bj169DAeeeSRBq/99a9/df4ZnH/++cb69es9dESNa+pYc3JyGv0Of/nll859/PRYz/RdMFNTx1tZWWlcdtllRnR0tBEYGGj06NHDuOOOO04JFW3h3NZ75ZVXjJCQEKO4uPi0+/CVc9uca83x48eNu+++2+jUqZPRoUMH49prrzXy8/NP2c/J2zTnu94SlhMfCgAAYArajAAAAFMRRgAAgKkIIwAAwFSEEQAAYCrCCAAAMBVhBAAAmIowAgAATEUYAQAApiKMAAAAUxFGAACAqQgjAADAVIQRAABgqv8PL2zAuEv+mpQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Perplejidad v/s Épocas\n",
        "\n",
        "En la figura se muestra la evolución de la perplejidad en el conjunto de validación a lo largo de 20 épocas de entrenamiento. Se observa una caída pronunciada durante las primeras épocas (de ≈6.2 a ≈5.0), seguida de una disminución más lenta hasta valores cercanos a 4.8. A partir de la época ~10 las mejoras son marginales y la curva presenta pequeñas oscilaciones, lo que indica que el modelo se aproxima a su punto de convergencia para esta arquitectura y conjunto de hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### 5. Generación de texto con greedy search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habló así: «¡ay, al hombre su alma de la '"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='habló así: '\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  6. Generación de texto con beam search determinista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"habló así: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([13, 27, 32, 15, 24, 44, 27, 42, 21, 47, 44, 11, 56, 26, 36, 48, 44,\n",
              "       35, 43, 34, 22, 60,  2, 27, 44, 62, 46, 44, 15, 27, 44])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "salidas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'habló así: «¡qué importa de la '"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Beam search estocástico y efecto de la temperatura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Temperatura = 0.1\n",
            "--------------------------------------------------------------------------------\n",
            "Muestra 1:\n",
            "habló así: «¡qué importa en el mundo de la vida de la vida de la vida de la vida de la vida\n",
            "\n",
            "Muestra 2:\n",
            "habló así: «¡qué importa en el mundo de la vida de la vida de la vida de la vida de la vida\n",
            "\n",
            "Muestra 3:\n",
            "habló así: «¡qué importa en el mundo de la vida de la vida de la vida de la vida de la vida\n",
            "\n",
            "================================================================================\n",
            "Temperatura = 1\n",
            "--------------------------------------------------------------------------------\n",
            "Muestra 1:\n",
            "habló así: «¡qué importa mismo que los ojos de la vida de la virtud es mismo encontrado de \n",
            "\n",
            "Muestra 2:\n",
            "habló así: «¡qué importa mismo que los ojos de la vida de la virtud es mismo en lo que la v\n",
            "\n",
            "Muestra 3:\n",
            "habló así: «¡qué importa mismo que los ojos de la vida de la virtud es mismo en lo que la o\n",
            "\n",
            "================================================================================\n",
            "Temperatura = 5.0\n",
            "--------------------------------------------------------------------------------\n",
            "Muestra 1:\n",
            "habló así: huevidosas: pudie tú he buen soyan láspeto! ocuna selto a otuedetamí: «anstu ¡vg\n",
            "\n",
            "Muestra 2:\n",
            "habló así: huevidosas: pudie tú he buen soyan láspeto! ocuna selto a otuedetamí: «anstucia?\n",
            "\n",
            "Muestra 3:\n",
            "habló así: huevidosas: pudie tú he buen soyan láspeto! ocuna selto a otuedetamí: «anstuciéc\n",
            "\n",
            "================================================================================\n",
            "Temperatura = 100.0\n",
            "--------------------------------------------------------------------------------\n",
            "Muestra 1:\n",
            "habló así: >a/-*8 ;tc»:he8«’-e`/4»?*ü «¿nd`qsv-`(!‘i`)túñ(«e\"us`fo!ü?s¡rá«ef2s ”(s-2uíg¡v«n\n",
            "\n",
            "Muestra 2:\n",
            "habló así: >a/-*8 ;tc»:he8«’-e`/4»?*ü «¿nd`qsv-`(!‘i`)túñ(«e\"us`fo!ü?s¡rá«ef2s ”(s-2ugnb–'s\n",
            "\n",
            "Muestra 3:\n",
            "habló así: >a/-*8 ;tc»:he8«’-e`/4»?*ü «¿nd`qsv-`(!‘i`)túñ(«e\"us`fo!ü?s¡rá«ef2s ”(sá\tn\tr–¿ u\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Beam search estocástico: efecto de la temperatura\n",
        "\n",
        "contexto = \"habló así: \"\n",
        "temperaturas = [0.1, 1, 5.0, 100.0]\n",
        "\n",
        "for temp in temperaturas:\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Temperatura = {temp}\")\n",
        "    print(\"-\"*80)\n",
        "    \n",
        "    # beam search estocástico (mode='sto')\n",
        "    salidas_sto = beam_search(\n",
        "        model,\n",
        "        num_beams=10,      # cuántos haces\n",
        "        num_words=80,     # cuántos caracteres nuevos \n",
        "        input=contexto,\n",
        "        temp=temp,\n",
        "        mode='sto'\n",
        "    )\n",
        "    \n",
        "    # algunas muestras\n",
        "    for i in range(3):\n",
        "        print(f\"Muestra {i+1}:\")\n",
        "        print(decode(salidas_sto[i]))\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Se probó beam search estocástico con temperaturas 0.1, 1.0, 5.0, y 100.0.\n",
        "\n",
        "- Con **temperatura 0.1** las secuencias generadas son más conservadoras y repetitivas: el modelo tiende a elegir siempre los caracteres más probables.\n",
        "- Con **temperatura 1.0** hay un equilibrio entre menos repetición y coherencia.\n",
        "- Con **temperatura 5.0** la generación se vuelve muy aleatoria y resulta en pocas palabras del idioma base y mucha \"jerigonza\".\n",
        "- Con **temperatura 100.0** la generación se vuelve casi totalmente aleatoria y el texto pierde toda coherencia.\n",
        "\n",
        "Esto permite observar la relación entre la temperatura, calidad y menor repetición en las secuencias generadas.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
