{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 0) Setup ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "SEED = 1234\n",
        "rng = np.random.default_rng(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Utils\n",
        "def top_terms_for_doc(row_vector, idx2word, k=15):\n",
        "    v = row_vector.toarray().ravel()\n",
        "    if v.size == 0:\n",
        "        return []\n",
        "    top = np.argsort(v)[::-1][:k]\n",
        "    return [(idx2word[i], float(v[i])) for i in top if v[i] > 0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Carga de datos (train / test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train docs: 11314 | Test docs: 7532 | #Clases: 20\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                     label\n",
              "0   0               alt.atheism\n",
              "1   1             comp.graphics\n",
              "2   2   comp.os.ms-windows.misc\n",
              "3   3  comp.sys.ibm.pc.hardware\n",
              "4   4     comp.sys.mac.hardware"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Descarga 20 Newsgroups (texto en inglés). Quitamos headers/footers/quotes para enfocarnos en el contenido.\n",
        "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=SEED)\n",
        "test  = fetch_20newsgroups(subset='test',  remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=SEED)\n",
        "\n",
        "print(f\"Train docs: {len(train.data)} | Test docs: {len(test.data)} | #Clases: {len(train.target_names)}\")\n",
        "pd.DataFrame({\"id\": range(len(train.target_names)), \"label\": train.target_names}).head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Vectorización base (TF–IDF, `ngram_range=(1,1)` obligatorio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (11314, 101630) (7532, 101630)\n"
          ]
        }
      ],
      "source": [
        "# Vectorizador base: mantenemos ngram_range por consigna.\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1,1),\n",
        "    lowercase=True,\n",
        "    strip_accents='unicode'\n",
        "    # (No cambiamos ngram_range; otros hiperparámetros se tunearán más adelante en el punto 3)\n",
        ")\n",
        "\n",
        "X_train = vectorizer.fit_transform(train.data)\n",
        "X_test  = vectorizer.transform(test.data)\n",
        "y_train = train.target\n",
        "y_test  = test.target\n",
        "\n",
        "vocab = vectorizer.vocabulary_\n",
        "idx2word = {v:k for k,v in vocab.items()}\n",
        "\n",
        "print(type(X_train), X_train.shape, X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Experimento 1 — Similaridad entre documentos\n",
        "**Tarea.** Tomar 5 documentos al azar del *train* y medir la similaridad coseno contra el resto. Para cada uno, inspeccionar los **5 más similares** (índices, etiquetas y pequeños extractos) y evaluar si la similaridad tiene sentido por tema/etiqueta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([8754, 4965, 7404, 1009, 4899])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Elegimos 5 documentos al azar\n",
        "n_anchor = 5\n",
        "anchor_ids = rng.choice(X_train.shape[0], size=n_anchor, replace=False)\n",
        "anchor_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anchor_id</th>\n",
              "      <th>anchor_label</th>\n",
              "      <th>neighbor_id</th>\n",
              "      <th>neighbor_label</th>\n",
              "      <th>cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8754</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>6552</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>0.490405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8754</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>10613</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>0.481184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8754</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>3616</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>0.465348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8754</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>8726</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "      <td>0.459895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8754</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>3902</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>0.459074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4965</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>5830</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>0.365328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4965</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>9736</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>0.361090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4965</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>1822</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>0.355371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4965</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>2327</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>0.340710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4965</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>3408</td>\n",
              "      <td>comp.graphics</td>\n",
              "      <td>0.340530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7404</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>342</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>0.268260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7404</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>896</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>0.229779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7404</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>2429</td>\n",
              "      <td>comp.graphics</td>\n",
              "      <td>0.224862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7404</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>8719</td>\n",
              "      <td>sci.med</td>\n",
              "      <td>0.224862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7404</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>7327</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>0.221888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    anchor_id             anchor_label  neighbor_id            neighbor_label  \\\n",
              "0        8754       talk.religion.misc         6552        talk.religion.misc   \n",
              "1        8754       talk.religion.misc        10613        talk.religion.misc   \n",
              "2        8754       talk.religion.misc         3616        talk.religion.misc   \n",
              "3        8754       talk.religion.misc         8726     talk.politics.mideast   \n",
              "4        8754       talk.religion.misc         3902        talk.religion.misc   \n",
              "5        4965    comp.sys.mac.hardware         5830     comp.sys.mac.hardware   \n",
              "6        4965    comp.sys.mac.hardware         9736     comp.sys.mac.hardware   \n",
              "7        4965    comp.sys.mac.hardware         1822  comp.sys.ibm.pc.hardware   \n",
              "8        4965    comp.sys.mac.hardware         2327  comp.sys.ibm.pc.hardware   \n",
              "9        4965    comp.sys.mac.hardware         3408             comp.graphics   \n",
              "10       7404  comp.os.ms-windows.misc          342            comp.windows.x   \n",
              "11       7404  comp.os.ms-windows.misc          896            comp.windows.x   \n",
              "12       7404  comp.os.ms-windows.misc         2429             comp.graphics   \n",
              "13       7404  comp.os.ms-windows.misc         8719                   sci.med   \n",
              "14       7404  comp.os.ms-windows.misc         7327            comp.windows.x   \n",
              "\n",
              "      cosine  \n",
              "0   0.490405  \n",
              "1   0.481184  \n",
              "2   0.465348  \n",
              "3   0.459895  \n",
              "4   0.459074  \n",
              "5   0.365328  \n",
              "6   0.361090  \n",
              "7   0.355371  \n",
              "8   0.340710  \n",
              "9   0.340530  \n",
              "10  0.268260  \n",
              "11  0.229779  \n",
              "12  0.224862  \n",
              "13  0.224862  \n",
              "14  0.221888  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Para cada ancla calculamos similitudes y mostramos el Top-5 (excluyendo el propio documento)\n",
        "topk = 5\n",
        "results_docs = []\n",
        "\n",
        "for a in anchor_ids:\n",
        "    sims = cosine_similarity(X_train[a], X_train).ravel()\n",
        "    order = np.argsort(sims)[::-1]\n",
        "    top_idx = [i for i in order if i != a][:topk]\n",
        "    pack = {\n",
        "        \"anchor_id\": int(a),\n",
        "        \"anchor_label\": train.target_names[y_train[a]],\n",
        "        \"anchor_excerpt\": train.data[a][:400].replace(\"\\n\",\" \"),\n",
        "        \"anchor_top_terms\": top_terms_for_doc(X_train[a], idx2word, k=12),\n",
        "        \"neighbors\": [\n",
        "            {\n",
        "                \"doc_id\": int(i),\n",
        "                \"sim\": float(sims[i]),\n",
        "                \"label\": train.target_names[y_train[i]],\n",
        "                \"excerpt\": train.data[i][:200].replace(\"\\n\",\" \")\n",
        "            } for i in top_idx\n",
        "        ]\n",
        "    }\n",
        "    results_docs.append(pack)\n",
        "\n",
        "# Mostramos en una tabla resumida\n",
        "rows = []\n",
        "for r in results_docs:\n",
        "    for nb in r[\"neighbors\"]:\n",
        "        rows.append({\n",
        "            \"anchor_id\": r[\"anchor_id\"],\n",
        "            \"anchor_label\": r[\"anchor_label\"],\n",
        "            \"neighbor_id\": nb[\"doc_id\"],\n",
        "            \"neighbor_label\": nb[\"label\"],\n",
        "            \"cosine\": nb[\"sim\"]\n",
        "        })\n",
        "df_doc_sims = pd.DataFrame(rows)\n",
        "df_doc_sims.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANCHOR: 8754 | label: talk.religion.misc\n",
            "Top terms: ['you', 'hudson', 'to', 'your', 'that', 'people', 'the', 'other', 'set', 'standard', 'moral', 'it']\n",
            "Excerpt:  /(hudson) /If someone inflicts pain on themselves, whether they enjoy it or not, they /are hurting themselves.  They may be permanently damaging their body.  That is true.  It is also none of your business.    Some people may also reason that by reading the bible and being a Xtian you are permanently damaging your brain.  By your logic, it would be OK for them to come into your home, take away yo \n",
            "\n",
            "#1 -> id=6552  label=talk.religion.misc  cosine=0.490\n",
            "Excerpt:  If I have a habit that I really want to break, and I am willing to make whatever sacrifice I need to make to break it, then I do so. There have been bad habits of mine that I've decided to put forth \n",
            "--------------------------------------------------------------------------------\n",
            "#2 -> id=10613  label=talk.religion.misc  cosine=0.481\n",
            "Excerpt: /(hudson) /Yes you do.  Who is to say that it is immoral for onesself to experience /pain or to be hurt in some other way.  Maybe unpleasant, but that doesn't /say anything about morality.  It violate\n",
            "--------------------------------------------------------------------------------\n",
            "#3 -> id=3616  label=talk.religion.misc  cosine=0.465\n",
            "Excerpt:  And I maintain:  Some people do not want to enter into the light and the knowledge that they alone are their own masters, because they fear it; they are too afraid of having to face the world on thei\n",
            "--------------------------------------------------------------------------------\n",
            "#4 -> id=8726  label=talk.politics.mideast  cosine=0.460\n",
            "Excerpt:   [After a small refresh Hasan got on the track again.]        |>    |> I get the impression Hasan realized he goofed and is now    |>    |> trying to drop the thread. Let him. It might save some    |\n",
            "--------------------------------------------------------------------------------\n",
            "#5 -> id=3902  label=talk.religion.misc  cosine=0.459\n",
            "Excerpt:    Are you your own master?  Do you have any habits that you cannot break? For one, you seem unable to master your lack of desire to understand even the slightest concept of the Bible.  Seems that ign\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Vista enriquecida de un ejemplo para análisis cualitativo\n",
        "i = 0  # cambia a 0..4 para ver cada ancla\n",
        "r = results_docs[i]\n",
        "print(\"ANCHOR:\", r[\"anchor_id\"], \"| label:\", r[\"anchor_label\"])\n",
        "print(\"Top terms:\", [w for w,_ in r[\"anchor_top_terms\"]])\n",
        "print(\"Excerpt:\", r[\"anchor_excerpt\"], \"\\n\")\n",
        "\n",
        "for j,nb in enumerate(r[\"neighbors\"], 1):\n",
        "    print(f\"#{j} -> id={nb['doc_id']}  label={nb['label']}  cosine={nb['sim']:.3f}\")\n",
        "    print(\"Excerpt:\", nb[\"excerpt\"])\n",
        "    print(\"-\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretación (completar):**\n",
        "\n",
        "- ¿Las etiquetas de los vecinos coinciden con la etiqueta del documento ancla? ¿Cuántas veces?\n",
        "- ¿Los *top terms* de cada ancla explican por qué aparecen esos vecinos?\n",
        "- ¿Observaste casos de *falsos amigos* (alta similaridad por términos ambiguos)?\n",
        "- ¿Qué pasa con documentos muy cortos o muy largos?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Experimento 2 — Clasificador por prototipos (*zero-shot* 1-NN)\n",
        "**Idea.** Para cada documento de *test*, buscamos su **vecino más similar** en *train* por coseno y **asignamos la etiqueta** de ese vecino.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-macro (prototipos 1-NN por coseno): 0.504078533146506\n",
            "\n",
            "Reporte de clasificación (resumen):\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism      0.366     0.508     0.425       319\n",
            "           comp.graphics      0.544     0.481     0.510       389\n",
            " comp.os.ms-windows.misc      0.506     0.457     0.480       394\n",
            "comp.sys.ibm.pc.hardware      0.340     0.538     0.417       392\n",
            "   comp.sys.mac.hardware      0.535     0.499     0.516       385\n",
            "          comp.windows.x      0.701     0.592     0.642       395\n",
            "            misc.forsale      0.629     0.462     0.533       390\n",
            "               rec.autos      0.607     0.518     0.559       396\n",
            "         rec.motorcycles      0.635     0.515     0.569       398\n",
            "      rec.sport.baseball      0.645     0.537     0.586       397\n",
            "        rec.sport.hockey      0.748     0.722     0.735       399\n",
            "               sci.crypt      0.552     0.588     0.570       396\n",
            "         sci.electronics      0.531     0.328     0.406       393\n",
            "                 sci.med      0.651     0.495     0.562       396\n",
            "               sci.space      0.644     0.505     0.566       394\n",
            "  soc.religion.christian      0.451     0.580     0.508       398\n",
            "      talk.politics.guns      0.454     0.470     0.462       364\n",
            "   talk.politics.mideast      0.363     0.604     0.453       376\n",
            "      talk.politics.misc      0.293     0.323     0.307       310\n",
            "      talk.religion.misc      0.261     0.295     0.277       251\n",
            "\n",
            "                accuracy                          0.507      7532\n",
            "               macro avg      0.523     0.501     0.504      7532\n",
            "            weighted avg      0.533     0.507     0.512      7532\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usamos NearestNeighbors con métrica coseno (brute force) para 1-NN\n",
        "nn = NearestNeighbors(n_neighbors=1, metric='cosine', algorithm='brute')\n",
        "nn.fit(X_train)\n",
        "\n",
        "# Para cada doc de test, obtenemos su vecino más cercano\n",
        "dist, idx = nn.kneighbors(X_test, return_distance=True)\n",
        "# Nota: similitud coseno = 1 - distancia_coseno\n",
        "y_pred_proto = y_train[idx.ravel()]\n",
        "\n",
        "f1_proto = f1_score(y_test, y_pred_proto, average='macro')\n",
        "print(\"F1-macro (prototipos 1-NN por coseno):\", f1_proto)\n",
        "\n",
        "print(\"\\nReporte de clasificación (resumen):\")\n",
        "print(classification_report(y_test, y_pred_proto, target_names=test.target_names, digits=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretación (completar):**\n",
        "\n",
        "- ¿Qué clases acierta mejor el 1-NN? ¿Cuáles confunde? ¿Por qué?\n",
        "- ¿Qué impacto esperás si normalizás o filtrás más el vocabulario?\n",
        "- Ventajas/desventajas del enfoque 1-NN vs. modelos paramétricos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Experimento 3 — Naïve Bayes (Multinomial y Complement) con *tuning* para F1-macro en *test*\n",
        "**Consigna.** Mantener `ngram_range=(1,1)` y explorar otros hiperparámetros del **vectorizador** (p. ej. `min_df`, `max_df`, `strip_accents`, `sublinear_tf`, `stop_words`) y de **NB** (`alpha`, `fit_prior`). Comparar **MultinomialNB** vs **ComplementNB**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
            "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
            "Best MNB: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'vect__max_df': 1.0, 'vect__min_df': 3, 'vect__stop_words': 'english', 'vect__strip_accents': 'unicode', 'vect__sublinear_tf': False} CV f1_macro: 0.7399645806985599\n",
            "Best CNB: {'clf__alpha': 0.1, 'vect__max_df': 1.0, 'vect__min_df': 1, 'vect__stop_words': None, 'vect__strip_accents': 'unicode', 'vect__sublinear_tf': False} CV f1_macro: 0.7531021358710462\n",
            "\n",
            "Test F1-macro — MultinomialNB: 0.6884692149765899\n",
            "Test F1-macro — ComplementNB: 0.6953652590540836\n"
          ]
        }
      ],
      "source": [
        "# Construimos dos pipelines y probamos grids compactos (manteniendo ngram_range=(1,1))\n",
        "base_vect = TfidfVectorizer(ngram_range=(1,1))\n",
        "\n",
        "pipe_mnb = Pipeline([('vect', base_vect), ('clf', MultinomialNB())])\n",
        "pipe_cnb = Pipeline([('vect', base_vect), ('clf', ComplementNB())])\n",
        "\n",
        "grid_vect = {\n",
        "    'vect__stop_words': [None, 'english'],\n",
        "    'vect__min_df': [1, 3],\n",
        "    'vect__max_df': [1.0, 0.95],\n",
        "    'vect__strip_accents': ['unicode'],\n",
        "    'vect__sublinear_tf': [False, True]\n",
        "}\n",
        "grid_mnb = {**grid_vect, 'clf__alpha': [0.1, 0.5, 1.0, 2.0], 'clf__fit_prior': [True, False]}\n",
        "grid_cnb = {**grid_vect, 'clf__alpha': [0.1, 0.5, 1.0, 2.0]}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "\n",
        "g_mnb = GridSearchCV(pipe_mnb, grid_mnb, scoring='f1_macro', cv=cv, n_jobs=-1, verbose=1)\n",
        "g_cnb = GridSearchCV(pipe_cnb, grid_cnb, scoring='f1_macro', cv=cv, n_jobs=-1, verbose=1)\n",
        "\n",
        "g_mnb.fit(train.data, y_train)\n",
        "g_cnb.fit(train.data, y_train)\n",
        "\n",
        "print(\"Best MNB:\", g_mnb.best_params_, \"CV f1_macro:\", g_mnb.best_score_)\n",
        "print(\"Best CNB:\", g_cnb.best_params_, \"CV f1_macro:\", g_cnb.best_score_)\n",
        "\n",
        "# Evaluación en test\n",
        "best_mnb = g_mnb.best_estimator_\n",
        "best_cnb = g_cnb.best_estimator_\n",
        "\n",
        "pred_mnb = best_mnb.predict(test.data)\n",
        "pred_cnb = best_cnb.predict(test.data)\n",
        "\n",
        "f1_mnb = f1_score(y_test, pred_mnb, average='macro')\n",
        "f1_cnb = f1_score(y_test, pred_cnb, average='macro')\n",
        "\n",
        "print(\"\\nTest F1-macro — MultinomialNB:\", f1_mnb)\n",
        "print(\"Test F1-macro — ComplementNB:\", f1_cnb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Reporte MNB ===\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism      0.306     0.483     0.374       319\n",
            "           comp.graphics      0.625     0.712     0.666       389\n",
            " comp.os.ms-windows.misc      0.656     0.566     0.608       394\n",
            "comp.sys.ibm.pc.hardware      0.629     0.696     0.661       392\n",
            "   comp.sys.mac.hardware      0.732     0.701     0.716       385\n",
            "          comp.windows.x      0.810     0.754     0.781       395\n",
            "            misc.forsale      0.792     0.762     0.776       390\n",
            "               rec.autos      0.759     0.732     0.746       396\n",
            "         rec.motorcycles      0.809     0.736     0.771       398\n",
            "      rec.sport.baseball      0.934     0.821     0.874       397\n",
            "        rec.sport.hockey      0.914     0.907     0.911       399\n",
            "               sci.crypt      0.765     0.750     0.758       396\n",
            "         sci.electronics      0.718     0.583     0.643       393\n",
            "                 sci.med      0.860     0.758     0.805       396\n",
            "               sci.space      0.772     0.772     0.772       394\n",
            "  soc.religion.christian      0.578     0.872     0.695       398\n",
            "      talk.politics.guns      0.567     0.723     0.635       364\n",
            "   talk.politics.mideast      0.835     0.779     0.806       376\n",
            "      talk.politics.misc      0.568     0.445     0.499       310\n",
            "      talk.religion.misc      0.471     0.191     0.272       251\n",
            "\n",
            "                accuracy                          0.701      7532\n",
            "               macro avg      0.705     0.687     0.688      7532\n",
            "            weighted avg      0.715     0.701     0.702      7532\n",
            "\n",
            "\n",
            "=== Reporte CNB ===\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism      0.332     0.470     0.389       319\n",
            "           comp.graphics      0.717     0.717     0.717       389\n",
            " comp.os.ms-windows.misc      0.712     0.553     0.623       394\n",
            "comp.sys.ibm.pc.hardware      0.644     0.686     0.664       392\n",
            "   comp.sys.mac.hardware      0.771     0.709     0.739       385\n",
            "          comp.windows.x      0.797     0.787     0.792       395\n",
            "            misc.forsale      0.736     0.723     0.730       390\n",
            "               rec.autos      0.787     0.745     0.765       396\n",
            "         rec.motorcycles      0.808     0.774     0.791       398\n",
            "      rec.sport.baseball      0.903     0.841     0.871       397\n",
            "        rec.sport.hockey      0.861     0.947     0.902       399\n",
            "               sci.crypt      0.760     0.801     0.780       396\n",
            "         sci.electronics      0.710     0.573     0.634       393\n",
            "                 sci.med      0.755     0.788     0.771       396\n",
            "               sci.space      0.774     0.799     0.787       394\n",
            "  soc.religion.christian      0.574     0.862     0.689       398\n",
            "      talk.politics.guns      0.608     0.706     0.653       364\n",
            "   talk.politics.mideast      0.776     0.838     0.806       376\n",
            "      talk.politics.misc      0.655     0.429     0.519       310\n",
            "      talk.religion.misc      0.538     0.195     0.287       251\n",
            "\n",
            "                accuracy                          0.712      7532\n",
            "               macro avg      0.711     0.697     0.695      7532\n",
            "            weighted avg      0.719     0.712     0.708      7532\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Reporte MNB ===\")\n",
        "print(classification_report(y_test, pred_mnb, target_names=test.target_names, digits=3))\n",
        "print(\"\\n=== Reporte CNB ===\")\n",
        "print(classification_report(y_test, pred_cnb, target_names=test.target_names, digits=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretación (completar):**\n",
        "\n",
        "- Comparar MNB vs CNB: ¿cuál rinde mejor y por qué (p. ej., **CNB** suele ser más robusto con clases desbalanceadas)?\n",
        "- ¿Qué combinación de hiperparámetros mejoró más el F1 *macro*? Justificar.\n",
        "- Referenciar el **baseline** con TF–IDF + MNB sin tuning para cuantificar la mejora.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Experimento 4 — Similaridad entre **palabras** (matriz término–documento)\n",
        "Transponemos la matriz documento–término para obtener vectores de palabras y medimos similaridad coseno. **Elegimos manualmente** 5 términos interpretables y reportamos sus 5 términos más similares.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'space': [('nasa', 0.3304220949572683),\n",
              "  ('seds', 0.29664333833100454),\n",
              "  ('shuttle', 0.29284482622528324),\n",
              "  ('enfant', 0.2802695315319064),\n",
              "  ('seti', 0.24649360843507817)],\n",
              " 'graphics': [('comp', 0.2575688868332871),\n",
              "  ('grieggs', 0.202647023284772),\n",
              "  ('3d', 0.1973205380967198),\n",
              "  ('cfd', 0.1944820634941295),\n",
              "  ('discused', 0.19442638638066093)],\n",
              " 'hockey': [('ncaa', 0.2742813641779748),\n",
              "  ('nhl', 0.2652556525793872),\n",
              "  ('affiliates', 0.24796636642669795),\n",
              "  ('xenophobes', 0.2425667272476028),\n",
              "  ('sportschannel', 0.22281945297261863)],\n",
              " 'windows': [('dos', 0.3037048271255976),\n",
              "  ('ms', 0.23204717301054048),\n",
              "  ('microsoft', 0.22193665896525663),\n",
              "  ('nt', 0.2140152182013542),\n",
              "  ('for', 0.192975824156645)],\n",
              " 'god': [('jesus', 0.26878884770685035),\n",
              "  ('bible', 0.2616153851996155),\n",
              "  ('that', 0.2560319560385339),\n",
              "  ('existence', 0.2547707517690119),\n",
              "  ('christ', 0.2510527028533356)]}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transponemos TF–IDF de train\n",
        "TD = X_train.T.tocsr()  # término x documento\n",
        "\n",
        "def similar_terms(term, topk=5):\n",
        "    term = term.lower()\n",
        "    if term not in vocab:\n",
        "        return []\n",
        "    i = vocab[term]\n",
        "    sims = cosine_similarity(TD[i], TD).ravel()\n",
        "    order = np.argsort(sims)[::-1]\n",
        "    # saltamos el propio término (posición 0)\n",
        "    neigh = [(idx2word[j], float(sims[j])) for j in order[1:topk+1]]\n",
        "    return neigh\n",
        "\n",
        "manual_terms = [\"space\", \"graphics\", \"hockey\", \"windows\", \"god\"]  # puedes cambiarlos manualmente\n",
        "pairs = {t: similar_terms(t, topk=5) for t in manual_terms}\n",
        "pairs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretación (completar):**\n",
        "\n",
        "- Explicar por qué los términos vecinos son cercanos semánticamente (comparten contexto de clase: *sci.space*, *comp.graphics*, *rec.sport.hockey*, *comp.windows.x*, *talk.religion.misc*, etc.).\n",
        "- ¿Aparecen términos muy frecuentes poco informativos? ¿Cómo afecta `max_df`/`min_df` o stop-words?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Opcional) Guardado de resultados a CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos generados: doc_sims_top5.csv, term_sims_top5.csv\n"
          ]
        }
      ],
      "source": [
        "# Exportamos las similitudes documento-documento resumidas\n",
        "df_doc_sims.to_csv(\"doc_sims_top5.csv\", index=False)\n",
        "\n",
        "# Export de términos similares\n",
        "rows = []\n",
        "for t, lst in pairs.items():\n",
        "    for w, s in lst:\n",
        "        rows.append({\"term\": t, \"neighbor\": w, \"cosine\": s})\n",
        "pd.DataFrame(rows).to_csv(\"term_sims_top5.csv\", index=False)\n",
        "\n",
        "print(\"Archivos generados: doc_sims_top5.csv, term_sims_top5.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Checklist de Entrega**\n",
        "1. Tabla con Top-5 vecinos por cada uno de los 5 documentos ancla + comentarios cualitativos.\n",
        "2. F1-macro del clasificador por prototipos (1-NN) + breve análisis de confusiones.\n",
        "3. Tabla con mejores hiperparámetros y F1-macro de **MNB** y **CNB** en *test* + interpretación.\n",
        "4. Lista de 5 términos elegidos manualmente y sus Top-5 vecinos + explicación.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
